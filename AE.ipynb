{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "af52bcbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3908f240",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from tensorflow.keras.datasets import mnist\n",
    "import matplotlib.pyplot as plt\n",
    "# Load and preprocess the MNIST dataset\n",
    "(x_train, _), (x_test, _) = mnist.load_data()\n",
    "x_train = x_train.astype('float32') / 255.0\n",
    "x_test = x_test.astype('float32') / 255.0\n",
    "x_train = np.reshape(x_train, (len(x_train), 28, 28, 1)) \n",
    "x_test = np.reshape(x_test, (len(x_test), 28, 28, 1))\n",
    "\n",
    "# Add noise to the images\n",
    "noise_factor = 0.2\n",
    "x_train_noisy = x_train + noise_factor * np.random.normal(loc=0.0, scale=1.0, size=x_train.shape)\n",
    "x_test_noisy = x_test + noise_factor * np.random.normal(loc=0.0, scale=1.0, size=x_test.shape)\n",
    "\n",
    "x_train_noisy = np.clip(x_train_noisy, 0., 1.)\n",
    "x_test_noisy = np.clip(x_test_noisy, 0., 1.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "978161d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "base_model = load_model('final_feature.h5')\n",
    "base_model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9327cf41",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import euclidean_distances\n",
    "from sklearn.metrics.pairwise import cosine_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1668f8ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model:\n",
    "    def __init__(self,model):\n",
    "        self.model=model\n",
    "    def show(self):\n",
    "        path_cm = './confusion_matrix.png'\n",
    "        cm = Image.open(path_cm)\n",
    "        print(\"Model Evaluation Metrics:\")\n",
    "        display(cm)\n",
    "        path_results = './result_model.png'\n",
    "        results = Image.open(path_results)\n",
    "        print(\"\\nThis model was fine-tuned(VGG16) on Architectural Heritage Elements data.\")\n",
    "        print(\"Trained on 3000 images across 10 classes.\")\n",
    "        print(\"******************\")\n",
    "        print(\"Results on testing data:\")\n",
    "        display(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2f991e9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class KL_LOSS:\n",
    "    def _init__(self):\n",
    "        self.p=None\n",
    "        self.q=None\n",
    "    def hist(self,f1,f2):\n",
    "        print(\"Finding Probability Distribution of Features.\")\n",
    "        self.p, _ = np.histogram(f1, bins=256, range=(0, 256), density=True)\n",
    "        self.q, _ = np.histogram(f2, bins=256, range=(0, 256), density=True)\n",
    "        self.p = self.p[:256]\n",
    "        self.q = self.q[:256]\n",
    "        x_range = np.arange(256)\n",
    "        fig, axes = plt.subplots(2, 2, figsize=(12, 8))\n",
    "        axes[0, 0].plot(x_range, self.p, color='blue')\n",
    "        axes[0, 0].set_title('Density of hist1')\n",
    "        axes[0, 0].set_xlabel('Pixel Value')\n",
    "        axes[0, 0].set_ylabel('Density')\n",
    "\n",
    "        axes[0, 1].hist(np.arange(256), bins=256, weights=self.p, color='blue')\n",
    "        axes[0, 1].set_title('Histogram of hist1')\n",
    "        axes[0, 1].set_xlabel('Pixel Value')\n",
    "        axes[0, 1].set_ylabel('Frequency')\n",
    "\n",
    "        axes[1, 0].plot(x_range, self.q, color='red')\n",
    "        axes[1, 0].set_title('Density of hist2')\n",
    "\n",
    "        axes[1, 0].set_xlabel('Pixel Value')\n",
    "        axes[1, 0].set_ylabel('Density')\n",
    "\n",
    "        axes[1, 1].hist(np.arange(256), bins=256, weights=self.q, color='red')\n",
    "        axes[1, 1].set_title('Histogram of hist2')\n",
    "        axes[1, 1].set_xlabel('Pixel Value')\n",
    "        axes[1, 1].set_ylabel('Frequency')\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "        print(\"Done.\")\n",
    "        \n",
    "        \n",
    "    def kl_Loss(self,epsilon=1e-10):\n",
    "        try:\n",
    "            print(\"Finding KL Loss.\")\n",
    "            p=self.p\n",
    "            q=self.q\n",
    "            pq=sum(p[i] * log2((p[i] + epsilon) / (q[i] + epsilon)) for i in range(len(p)))\n",
    "            qp=sum(q[i] * log2((q[i] + epsilon) / (p[i] + epsilon)) for i in range(len(q)))\n",
    "            p='image1'\n",
    "            q='image2'\n",
    "            print(\" {},differs from another distribution, {}: {}\\n\\n\".format(p,q,pq))\n",
    "            print(\" {},differs from another distribution, {}: {}\\n\\n\".format(q,p,qp))\n",
    "            print(\"KL Loss:\",(pq+qp))\n",
    "        except Exception as e:\n",
    "            print(\"First call function hist.\")\n",
    "            print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6d21c51b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ContentLoss(Model,KL_LOSS):\n",
    "    def __init__(self,image1,image2,model):\n",
    "        self.model=model\n",
    "        super().__init__(self.model)\n",
    "        self.image1=image1\n",
    "        self.image2=image2\n",
    "        self.__list_fm1=None\n",
    "        self.__list_fm2=None\n",
    "        self.euclidean=[]\n",
    "        self.cosine=[]\n",
    "        self.contentloss=[]\n",
    "        self.kl_loss = KL_LOSS()\n",
    "        \n",
    "    def preprocess(self):\n",
    "        array1 = np.array(self.image1)\n",
    "        array2 = np.array(self.image2)\n",
    "        fig, axes = plt.subplots(1, 2)\n",
    "        axes[0].imshow(image1)\n",
    "        axes[0].set_title('Image 1')\n",
    "        axes[1].imshow(image2)\n",
    "        axes[1].set_title('Image 2')\n",
    "        plt.show()\n",
    "        \n",
    "    def generate_features(self):\n",
    "        image1 = np.expand_dims(self.image1, axis=0)\n",
    "        image2 = np.expand_dims(self.image2, axis=0)\n",
    "        self.__list_fm1 = self.model.predict(image1)\n",
    "        self.__list_fm2 = self.model.predict(image2)\n",
    "        print(\"done.\")\n",
    "        \n",
    "        \n",
    "    def sim_euc(self):\n",
    "        for i in range(len(self.__list_fm1)):\n",
    "            flat_features_image1 = self.__list_fm1[i].flatten()\n",
    "            flat_features_image2 = self.__list_fm2[i].flatten()\n",
    "            euclidean_distance = euclidean_distances([flat_features_image1], [flat_features_image2])\n",
    "            cosine_similarity_score = cosine_similarity([flat_features_image1], [flat_features_image2])\n",
    "            self.euclidean.append(euclidean_distance)\n",
    "            self.cosine.append(cosine_similarity_score)\n",
    "        print(\"done.\")\n",
    "            \n",
    "    def Contentloss(self):\n",
    "        print(\"inform:........preprocessing  image\")\n",
    "        self.preprocess()\n",
    "        print(\"Inform:........Finding features map of 2 given images.\")\n",
    "        self.generate_features()\n",
    "        print(\"Done..\\n\")\n",
    "        print(\"Finding distance.......\")\n",
    "        self.sim_euc()\n",
    "        print(\"Finding Content loss.............\\n\")\n",
    "        print(\"**********************************\")\n",
    "        for i in range(len(self.euclidean)):\n",
    "            print(f\"Euclidean Distance for feature map {i+1}: {self.euclidean[i]}\")\n",
    "            print(f\"Cosine Similarity for feature map {i+1}: {self.cosine[i]}\\n\")\n",
    "            print(\"****************************************************************\")\n",
    "        print(\"************************************\")\n",
    "        print(\"content loss: Giving 100 times to 5th and 10 times to 4th...\",100*self.euclidean[4]+10*self.euclidean[3])\n",
    "    \n",
    "    def kl(self):\n",
    "        self.kl_loss.hist(self.__list_fm1[4],self.__list_fm2[4])\n",
    "#         self.kl_loss.hist(self.image1,self.image2)\n",
    "        self.kl_loss.kl_Loss()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4a211338",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the Autoencoder architecture\n",
    "def autoencoder(input_shape):\n",
    "    # Encoder\n",
    "    encoder_input = layers.Input(shape=input_shape, name='encoder_input')\n",
    "    x = layers.Conv2D(32, (3, 3), activation='relu', padding='same')(encoder_input)\n",
    "    x = layers.MaxPooling2D((2, 2), padding='same')(x)\n",
    "    x = layers.Conv2D(64, (3, 3), activation='relu', padding='same')(x)\n",
    "    encoded = layers.MaxPooling2D((2, 2), padding='same')(x)\n",
    "\n",
    "    # Decoder\n",
    "    x = layers.Conv2D(64, (3, 3), activation='relu', padding='same')(encoded)\n",
    "    x = layers.UpSampling2D((2, 2))(x)\n",
    "    x = layers.Conv2D(32, (3, 3), activation='relu', padding='same')(x)\n",
    "    x = layers.UpSampling2D((2, 2))(x)\n",
    "    decoded = layers.Conv2D(1, (3, 3), activation='sigmoid', padding='same')(x)\n",
    "\n",
    "    autoencoder_model = models.Model(encoder_input, decoded, name='autoencoder')\n",
    "\n",
    "    return autoencoder_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4d770249",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shape = (28, 28, 1)  \n",
    "# Create the autoencoder model\n",
    "model = autoencoder(input_shape)\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "07ac977c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"autoencoder\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " encoder_input (InputLayer)  [(None, 28, 28, 1)]       0         \n",
      "                                                                 \n",
      " conv2d (Conv2D)             (None, 28, 28, 32)        320       \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2  (None, 14, 14, 32)        0         \n",
      " D)                                                              \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 14, 14, 64)        18496     \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPoolin  (None, 7, 7, 64)          0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 7, 7, 64)          36928     \n",
      "                                                                 \n",
      " up_sampling2d (UpSampling2  (None, 14, 14, 64)        0         \n",
      " D)                                                              \n",
      "                                                                 \n",
      " conv2d_3 (Conv2D)           (None, 14, 14, 32)        18464     \n",
      "                                                                 \n",
      " up_sampling2d_1 (UpSamplin  (None, 28, 28, 32)        0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_4 (Conv2D)           (None, 28, 28, 1)         289       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 74497 (291.00 KB)\n",
      "Trainable params: 74497 (291.00 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f94fe73",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c95ddc94",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'x_train_nosiy' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[11], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m epochs \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m      2\u001b[0m batch_size \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m128\u001b[39m\n\u001b[1;32m----> 3\u001b[0m history \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mfit(x_train, x_train_nosiy, epochs\u001b[38;5;241m=\u001b[39mepochs, batch_size\u001b[38;5;241m=\u001b[39mbatch_size, shuffle\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, validation_data\u001b[38;5;241m=\u001b[39m(x_test_noisy, x_test))\n",
      "\u001b[1;31mNameError\u001b[0m: name 'x_train_nosiy' is not defined"
     ]
    }
   ],
   "source": [
    "epochs = 1\n",
    "batch_size = 128\n",
    "history = model.fit(x_train, x_train_nosiy, epochs=epochs, batch_size=batch_size, shuffle=True, validation_data=(x_test_noisy, x_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57c80fc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot training loss and validation loss\n",
    "plt.plot(history.history['loss'], label='Training Loss')\n",
    "plt.plot(history.history['val_loss'], label='Validation Loss')\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3394a0f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "decoded_images = model.predict(x_test_noisy)\n",
    "n = 10 \n",
    "plt.figure(figsize=(20, 6))\n",
    "for i in range(n):\n",
    "    # Original Images\n",
    "    ax = plt.subplot(3, n, i + 1)\n",
    "    plt.imshow(x_test[i].reshape(28, 28))\n",
    "    plt.gray()\n",
    "    ax.get_xaxis().set_visible(False)\n",
    "    ax.get_yaxis().set_visible(False)\n",
    "\n",
    "    # Noisy Images\n",
    "    ax = plt.subplot(3, n, i + 1 + n)\n",
    "    plt.imshow(x_test_noisy[i].reshape(28, 28))\n",
    "    plt.gray()\n",
    "    ax.get_xaxis().set_visible(False)\n",
    "    ax.get_yaxis().set_visible(False)\n",
    "\n",
    "    # Denoised Images\n",
    "    ax = plt.subplot(3, n, i + 1 + 2 * n)\n",
    "    plt.imshow(decoded_images[i].reshape(28, 28))\n",
    "    plt.gray()\n",
    "    ax.get_xaxis().set_visible(False)\n",
    "    ax.get_yaxis().set_visible(False)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e8b671a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
